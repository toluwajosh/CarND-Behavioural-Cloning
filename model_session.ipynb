{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "## Import libraries\n",
    "import os\n",
    "import argparse\n",
    "import json\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from copy import deepcopy\n",
    "from sklearn.utils import shuffle\n",
    "from keras.models import Sequential, model_from_json\n",
    "from keras.layers import Dense, Dropout, Flatten, Lambda, ELU, MaxPooling2D\n",
    "from keras.regularizers import l2, activity_l2\n",
    "from keras.layers.convolutional import Convolution2D\n",
    "from keras.layers.core import Activation, Reshape\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "# data paths\n",
    "session_data = '../simulator-linux/session_data/driving_log.csv'\n",
    "udacity_data = '../simulator-linux/udacity_data/data/driving_log_edit.csv'\n",
    "path_prefix = '../simulator-linux/udacity_data/data/'"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# read data\n",
    "data_frame = pd.read_csv(udacity_data, usecols=['center', 'left', 'right', 'steer'])\n",
    "\n",
    "# shuffle the data\n",
    "data_frame = data_frame.sample(frac=1).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def augment_brightness(image):\n",
    "    \"\"\"\n",
    "    apply random brightness on the image\n",
    "    \"\"\"\n",
    "    image = cv2.cvtColor(image,cv2.COLOR_RGB2HSV)\n",
    "    random_bright = .25+np.random.uniform()\n",
    "    \n",
    "    # scaling up or down the V channel of HSV\n",
    "    image[:,:,2] = image[:,:,2]*random_bright\n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def trans_image(image,steer,trans_range, trans_y=False):\n",
    "    \"\"\"\n",
    "    translate image and compensate for the translation on the steering angle\n",
    "    \"\"\"\n",
    "    \n",
    "    rows, cols, chan = image.shape\n",
    "    \n",
    "    # horizontal translation with 0.008 steering compensation per pixel\n",
    "    tr_x = trans_range*np.random.uniform()-trans_range/2\n",
    "    steer_ang = steer + tr_x/trans_range*.4\n",
    "    \n",
    "    # option to disable vertical translation (vertical translation not necessary)\n",
    "    if trans_y:\n",
    "        tr_y = 40*np.random.uniform()-40/2\n",
    "    else:\n",
    "        tr_y = 0\n",
    "    \n",
    "    Trans_M = np.float32([[1,0,tr_x],[0,1,tr_y]])\n",
    "    image_tr = cv2.warpAffine(image,Trans_M,(cols,rows))\n",
    "    \n",
    "    return image_tr,steer_ang"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def crop_image(image, y1, y2, x1, x2):\n",
    "    \"\"\"\n",
    "    crop image into respective size\n",
    "    give: the crop extent\n",
    "    \"\"\"\n",
    "    return image[y1:y2, x1:x2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def im_process(image, steer_ang, train=True):\n",
    "    \"\"\"\n",
    "    Apply processing to image\n",
    "    \"\"\"    \n",
    "    # image size\n",
    "    im_y = image.shape[0]\n",
    "    im_x = image.shape[1]\n",
    "    \n",
    "    # translate image and compensate for steering angle\n",
    "    trans_range = 50\n",
    "    image, steer_ang = trans_image(image, steer_ang, trans_range) # , trans_y=True\n",
    "    \n",
    "    # crop image region of interest\n",
    "    image = crop_image(image, 20, 140, 0+trans_range, im_x-trans_range)\n",
    "    \n",
    "    # flip image (randomly)\n",
    "    if np.random.uniform()>= 0.5: #and abs(steer_ang) > 0.1\n",
    "        image = cv2.flip(image, 1)\n",
    "        steer_ang = -steer_ang\n",
    "    \n",
    "    # augment brightness\n",
    "    image = augment_brightness(image)\n",
    "    \n",
    "    # perturb steering with a bias\n",
    "    # steer_ang += np.random.normal(loc=0,scale=0.2)\n",
    "    \n",
    "    # image = cv2.cvtColor(image,cv2.COLOR_HSV2RGB)\n",
    "    \n",
    "    return image, steer_ang"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## data generator\n",
    "def generate_batch_samples(path, batch_size=128, path_prefix=''):\n",
    "    while 1:\n",
    "        batch_x, batch_y = [], []\n",
    "        \n",
    "        f = open(path)\n",
    "        for line in f:\n",
    "            \n",
    "            # select image\n",
    "            data_id = line.split(',')\n",
    "            cam_view = np.random.choice(['center', 'left', 'right'])\n",
    "            if cam_view == 'left':\n",
    "                ## left image\n",
    "                image = plt.imread(path_prefix+data_id[1].strip())\n",
    "                image, steering_angle = im_process(image, float(data_id[3])+.25)\n",
    "\n",
    "            elif cam_view == 'center':\n",
    "                ## centre image\n",
    "                image = plt.imread(path_prefix+data_id[0].strip())\n",
    "                image, steering_angle = im_process(image, float(data_id[3]))\n",
    "\n",
    "            elif cam_view == 'right':\n",
    "                ## right image\n",
    "                image = plt.imread(path_prefix+data_id[2].strip())\n",
    "                image, steering_angle = im_process(image, float(data_id[3])-.25)\n",
    "            \n",
    "            # resize image\n",
    "            image = cv2.resize(image, (200,66))\n",
    "            \n",
    "            batch_x.append(np.reshape(image, (1,66,200,3)))\n",
    "            batch_y.append(np.array([[steering_angle]]))\n",
    "            \n",
    "            if len(batch_x) == batch_size:\n",
    "                # shuffle batch\n",
    "                batch_x, batch_y, = shuffle(batch_x, batch_y, random_state=0)\n",
    "                \n",
    "                yield (np.vstack(batch_x), np.vstack(batch_y))\n",
    "                batch_x, batch_y = [], []\n",
    "    f.close()\n",
    "\n",
    "def generate_batch_validate(path, batch_size=128, path_prefix=''):\n",
    "    while 1:\n",
    "        batch_x, batch_y = [], []\n",
    "        \n",
    "        f = open(path)\n",
    "        for line in f:\n",
    "            \n",
    "            data_id = line.split(',')\n",
    "            cam_view = np.random.choice(['center', 'left', 'right'])\n",
    "\n",
    "            ## use only center image for validation\n",
    "            image = plt.imread(path_prefix+data_id[0].strip())\n",
    "            steering_angle = float(data_id[3])\n",
    "            \n",
    "            # crop region of interest and resize to model input size\n",
    "            image = crop_image(image, 20, 140, 50, 270)\n",
    "            image = cv2.resize(image, (200,66))\n",
    "            \n",
    "            # change colourspace\n",
    "            image = cv2.cvtColor(image,cv2.COLOR_RGB2HSV)\n",
    "            \n",
    "            batch_x.append(np.reshape(image, (1,66,200,3)))\n",
    "            batch_y.append(np.array([[steering_angle]]))\n",
    "            \n",
    "            if len(batch_x) == batch_size:\n",
    "                yield (np.vstack(batch_x), np.vstack(batch_y))\n",
    "                batch_x, batch_y = [], []\n",
    "    f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def save_fig(plot, fig_path, plt_title='', x_label='', y_label=''):\n",
    "    if plt_title:\n",
    "        plt.title(plt_title)\n",
    "    if x_label:\n",
    "        plt.xlabel(x_label)\n",
    "    if y_label:\n",
    "        plt.ylabel(y_label)\n",
    "    plt.savefig(fig_path)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# plot an histogram of a sample of the training data\n",
    "test_sample_gen = generate_batch_validate(session_data, batch_size=1)\n",
    "\n",
    "sample_angles = []\n",
    "for i in range(10000):\n",
    "    image, str_ang = next(test_sample_gen)\n",
    "    sample_angles.append(str_ang)\n",
    "sample_angles = np.vstack(sample_angles)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "n, bins, patches = plt.hist(sample_angles, 50, normed=1, facecolor='green', alpha=0.75)\n",
    "save_fig(plt, 'media/raw_data_sample_hist.jpg',\n",
    "        'Training Data Sample Histogram (before processing)',\n",
    "        x_label='Steering Angle')\n",
    "\n",
    "# plt.title('Training Data Sample Histogram (before processing)')\n",
    "# plt.xlabel('Steering Angle')\n",
    "# plt.savefig('media/raw_data_sample_hist.jpg')"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# preview image and preprocess pipeline\n",
    "\n",
    "# track 1\n",
    "im_name = '2017_01_21_00_17_08_493.jpg'\n",
    "image_r = plt.imread(\"../simulator-linux/session_data/IMG/right_\"+im_name)\n",
    "image_l = plt.imread(\"../simulator-linux/session_data/IMG/left_\"+im_name)\n",
    "image_c = plt.imread(\"../simulator-linux/session_data/IMG/center_\"+im_name)\n",
    "\n",
    "# track 2\n",
    "# image_c = plt.imread(\"../simulator-linux/track_2/IMG/center_2017_01_18_11_28_28_391.jpg\")\n",
    "steer = 0\n",
    "fig = plt.figure()\n",
    "aaa = fig.add_subplot(131)\n",
    "image_l, steer = im_process(image_l, steer+0.5)\n",
    "aaa.imshow(image_l)\n",
    "plt.xticks([])\n",
    "plt.yticks([])\n",
    "plt.title('left cam: {0:.2f}'.format(steer))\n",
    "\n",
    "steer = 0\n",
    "aaa = fig.add_subplot(132)\n",
    "image_c, steer = im_process(image_c, steer)\n",
    "aaa.imshow(image_c)\n",
    "plt.xticks([])\n",
    "plt.yticks([])\n",
    "plt.title('center cam: {0:.2f}'.format(steer))\n",
    "\n",
    "steer = 0\n",
    "aaa = fig.add_subplot(133)\n",
    "image_r, steer = im_process(image_r, steer-0.5)\n",
    "aaa.imshow(image_r)\n",
    "plt.xticks([])\n",
    "plt.yticks([])\n",
    "plt.title('right cam: {0:.2f}'.format(steer))\n",
    "plt.tight_layout()\n",
    "\n",
    "# save figure\n",
    "save_fig(plt, 'media/camera_views.jpg')\n",
    "\n",
    "# show_im = image_c[60:130, 50:250]\n",
    "# show_im = image_c[20:140,:]\n",
    "# show_im = image_c[20:140,:]\n",
    "# show_im = cv2.resize(show_im, (200,66))\n",
    "# print(show_im.shape)\n",
    "# plt.imshow(show_im)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def commaai_model(time_len=1):\n",
    "    ch, row, col = 3, 66, 200  # camera format\n",
    "\n",
    "    model = Sequential()\n",
    "    model.add(Lambda(lambda x: x/127.5 - 1.,\n",
    "            input_shape=(row, col, ch),\n",
    "            output_shape=(row, col, ch)))\n",
    "    model.add(Convolution2D(16, 8, 8, subsample=(4, 4), border_mode=\"same\"))\n",
    "    model.add(ELU())\n",
    "    model.add(Convolution2D(32, 5, 5, subsample=(2, 2), border_mode=\"same\"))\n",
    "    model.add(ELU())\n",
    "    model.add(Convolution2D(64, 5, 5, subsample=(2, 2), border_mode=\"same\"))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dropout(.2))\n",
    "    model.add(ELU())\n",
    "    model.add(Dense(512))\n",
    "    model.add(Dropout(.2))\n",
    "    model.add(ELU())\n",
    "    model.add(Dense(1))\n",
    "\n",
    "    model.compile(optimizer=\"adam\", loss=\"mse\")\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def commaai_mod_model(time_len=1):\n",
    "    ch, row, col = 3, 66, 200  # camera format\n",
    "    keep_prob = 0.2\n",
    "\n",
    "    model = Sequential()\n",
    "    model.add(Lambda(lambda x: x/127.5 - 1.,\n",
    "            input_shape=(row, col, ch),\n",
    "            output_shape=(row, col, ch)))\n",
    "    model.add(Convolution2D(16, 8, 8, subsample=(4, 4), border_mode=\"valid\"))\n",
    "    model.add(ELU())\n",
    "#     model.add(Dropout(keep_prob))\n",
    "    \n",
    "    model.add(Convolution2D(32, 5, 5, subsample=(2, 2), border_mode=\"valid\"))\n",
    "    model.add(ELU())\n",
    "    model.add(Dropout(keep_prob))\n",
    "    \n",
    "    model.add(Convolution2D(64, 5, 5, subsample=(2, 2), border_mode=\"valid\"))\n",
    "    model.add(ELU())\n",
    "    model.add(Dropout(keep_prob))\n",
    "    \n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(512))\n",
    "    model.add(Dropout(keep_prob))\n",
    "    model.add(ELU())\n",
    "    \n",
    "    model.add(Dense(128))\n",
    "    model.add(Dropout(keep_prob))\n",
    "    model.add(ELU())\n",
    "    \n",
    "    model.add(Dense(50))\n",
    "    model.add(ELU())\n",
    "    \n",
    "    model.add(Dense(1))\n",
    "\n",
    "    model.compile(optimizer=\"adam\", loss=\"mse\")\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Model architecture\n",
    "def nvidia_model(time_len=1):\n",
    "    ch, row, col = 3, 66, 200  # camera format\n",
    "    INIT='glorot_uniform' # 'he_normal', glorot_uniform\n",
    "    keep_prob = 0.2\n",
    "    reg_val = 0.01\n",
    "    \n",
    "    model = Sequential()\n",
    "    model.add(Lambda(lambda x: x/127.5 - 1.,\n",
    "            input_shape=(row, col, ch),\n",
    "            output_shape=(row, col, ch)))\n",
    "    model.add(Convolution2D(24, 5, 5, subsample=(2, 2), border_mode=\"valid\", init=INIT, W_regularizer=l2(reg_val)))\n",
    "    # W_regularizer=l2(reg_val)\n",
    "    model.add(ELU())\n",
    "    model.add(Dropout(keep_prob))\n",
    "\n",
    "    model.add(Convolution2D(36, 5, 5, subsample=(2, 2), border_mode=\"valid\", init=INIT))\n",
    "    model.add(ELU())\n",
    "    model.add(Dropout(keep_prob))\n",
    "    \n",
    "    model.add(Convolution2D(48, 5, 5, subsample=(2, 2), border_mode=\"valid\", init=INIT))\n",
    "    model.add(ELU())\n",
    "    model.add(Dropout(keep_prob))\n",
    "\n",
    "    model.add(Convolution2D(64, 3, 3, subsample=(1, 1), border_mode=\"valid\", init=INIT))\n",
    "    model.add(ELU())\n",
    "    model.add(Dropout(keep_prob))\n",
    "\n",
    "    model.add(Convolution2D(64, 3, 3, subsample=(1, 1), border_mode=\"valid\", init=INIT))\n",
    "    model.add(ELU())\n",
    "    model.add(Dropout(keep_prob))\n",
    "    \n",
    "    model.add(Flatten())\n",
    "\n",
    "    model.add(Dense(100))\n",
    "    model.add(ELU())\n",
    "    model.add(Dropout(0.2))\n",
    "    \n",
    "    model.add(Dense(50))\n",
    "    model.add(ELU())\n",
    "    model.add(Dropout(0.2))\n",
    "    \n",
    "    model.add(Dense(10))\n",
    "    model.add(ELU())\n",
    "    \n",
    "    model.add(Dense(1))\n",
    "\n",
    "    model.compile(optimizer=\"adam\", loss=\"mse\") # , metrics=['accuracy']\n",
    "    \n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "nvidia_model().summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# try to load a previous json model\n",
    "model_path = 'checkpoints/test_model'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Callbacks\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping, Callback, TensorBoard\n",
    "\n",
    "# a callback to save a list of the losses over each batch during training\n",
    "class LossHistory(Callback):\n",
    "    def on_train_begin(self, logs={}):\n",
    "        self.train_loss = []\n",
    "\n",
    "    def on_batch_end(self, batch, logs={}):\n",
    "        self.train_loss.append(logs.get('loss'))\n",
    "\n",
    "\n",
    "# a callback to save a list of the accuracies over each batch during training\n",
    "class AccHistory(Callback):\n",
    "    def on_train_begin(self, logs={}):\n",
    "        self.train_acc = []\n",
    "        \n",
    "    def on_batch_end(self, batch, logs={}):\n",
    "        self.train_acc.append(logs.get('acc'))\n",
    "\n",
    "loss_hist = LossHistory()\n",
    "acc_hist = AccHistory()\n",
    "early_stop = EarlyStopping(monitor='val_loss', patience=3, \n",
    "                           verbose=0, mode='min')\n",
    "checkpoint = ModelCheckpoint('checkpoints/'+model_path+'-{epoch:02d}-{val_loss:.4f}', \n",
    "                             monitor='val_loss',verbose=0, save_best_only=True, \n",
    "                             save_weights_only=False, mode='auto')\n",
    "tensor_board = TensorBoard('learn_log')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## Training and validation\n",
    "EPOCHS = 1\n",
    "\n",
    "# create model\n",
    "model = nvidia_model()\n",
    "\n",
    "try:\n",
    "    model.load_weights(model_path+'.h5')\n",
    "#     model.load_weights('checkpoints/nvidia_yuv_glorot_model-03-0.0187')\n",
    "    \n",
    "except IOError:\n",
    "    print ('no previous model found....\\n')\n",
    "\n",
    "# initialize generators\n",
    "my_samples_gen = generate_batch_samples(session_data, path_prefix='', batch_size=128)\n",
    "u_samples_gen = generate_batch_validate(udacity_data, path_prefix=path_prefix, batch_size=200)\n",
    "\n",
    "# train model\n",
    "model.fit_generator(\n",
    "    my_samples_gen,\n",
    "    samples_per_epoch=128*188, nb_epoch=EPOCHS,\n",
    "    validation_data=u_samples_gen,\n",
    "    nb_val_samples=24000,\n",
    "    callbacks=[early_stop, checkpoint]\n",
    ")\n",
    "\n",
    "# save model\n",
    "print(\"Saving model weights and configuration file...\")\n",
    "\n",
    "# if not os.path.exists(\"./outputs/steering_model\"):\n",
    "#     os.makedirs(\"./outputs/steering_model\")\n",
    "\n",
    "model.save_weights(model_path+'.h5', True)\n",
    "with open(model_path+'.json', 'w') as outfile:\n",
    "    json.dump(model.to_json(), outfile)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
